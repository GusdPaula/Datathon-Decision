{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWvq-kBkcfx6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udRUwmMqUvo5"
      },
      "source": [
        "## Step 1: Load and Parse the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dElYuSZTUlRB"
      },
      "outputs": [],
      "source": [
        "# Load JSON files\n",
        "with open(r'applicants.json', encoding='utf-8') as f:\n",
        "    applicants = json.load(f)\n",
        "\n",
        "with open(r'vagas.json', encoding='utf-8') as f:\n",
        "    jobs = json.load(f)\n",
        "\n",
        "with open(\"prospects.json\", encoding=\"utf-8\") as f:\n",
        "    prospects = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bRqLGJPU1s0"
      },
      "source": [
        "## Step 2: Extract Text (Skills & Descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVnczqMkU22v"
      },
      "outputs": [],
      "source": [
        "\n",
        "# From applicants:\n",
        "def extract_applicant_skills(applicant):\n",
        "    skills = applicant[\"informacoes_profissionais\"].get(\"conhecimentos_tecnicos\", \"\")\n",
        "    cv = applicant.get(\"cv_pt\", \"\")\n",
        "    return skills + \" \" + cv.lower()  # merge and normalize\n",
        "\n",
        "# From jobs\n",
        "def extract_job_requirements(job):\n",
        "    skills = job[\"perfil_vaga\"].get(\"competencia_tecnicas_e_comportamentais\", \"\")\n",
        "    activities = job[\"perfil_vaga\"].get(\"principais_atividades\", \"\")\n",
        "    return skills.lower() + \" \" + activities.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbUWe_mtVQ0W"
      },
      "source": [
        "##  Step 3: Create Matching Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui0Apgbss87r",
        "outputId": "8b477938-73a7-4ae2-8476-951d0012df60"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text, language='portuguese')\n",
        "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "applicant_ids = list(applicants.keys())\n",
        "job_ids = list(jobs.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaQMuedSs_Uu"
      },
      "outputs": [],
      "source": [
        "# Extract and preprocess texts\n",
        "applicant_texts = [\n",
        "    preprocess(extract_applicant_skills(applicants[aid]))\n",
        "    for aid in applicant_ids\n",
        "]\n",
        "\n",
        "job_texts = [\n",
        "    preprocess(extract_job_requirements(jobs[jid]))\n",
        "    for jid in job_ids\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "applicant_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooWubl29VSnC"
      },
      "outputs": [],
      "source": [
        "# Fit only on jobs\n",
        "vectorizer = TfidfVectorizer()\n",
        "job_vecs = vectorizer.fit_transform(job_texts)\n",
        "\n",
        "# Transform applicants using same vectorizer\n",
        "applicant_vecs = vectorizer.transform(applicant_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHqsN0wfwbc7"
      },
      "outputs": [],
      "source": [
        "similarity_matrix = cosine_similarity(applicant_vecs, job_vecs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#np.save('similarity_matrix', similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDA2KM8FcV2G"
      },
      "source": [
        "## Step 4: Recommend Top Jobs for an Applicant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIIFQXiGcUtC"
      },
      "outputs": [],
      "source": [
        "def show_recommendations_for_applicant(applicant_index, top_n=5):\n",
        "    applicant_id = applicant_ids[applicant_index]\n",
        "    applicant = applicants.get(applicant_id, {})\n",
        "\n",
        "    # Extract applicant details\n",
        "    name = applicant.get(\"infos_basicas\", {}).get(\"nome\", \"N/A\")\n",
        "    area = applicant.get(\"informacoes_profissionais\", {}).get(\"area_atuacao\", \"N/A\")\n",
        "    skills = applicant.get(\"informacoes_profissionais\", {}).get(\"conhecimentos_tecnicos\", \"N/A\")\n",
        "    academic = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_academico\", \"N/A\")\n",
        "    english = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_ingles\", \"N/A\")\n",
        "    spanish = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_espanhol\", \"N/A\")\n",
        "    cv_excerpt = applicant.get(\"cv_pt\", \"\").strip().replace(\"\\n\", \" \")[:300] + \"...\"\n",
        "\n",
        "    # Show applicant info once\n",
        "    print(f\"\\n=== üßë Applicant: {name} (ID: {applicant_id}) ===\")\n",
        "    print(f\"√Årea de Atua√ß√£o: {area}\")\n",
        "    print(f\"Conhecimentos T√©cnicos: {skills}\")\n",
        "    print(f\"Forma√ß√£o: {academic} | Ingl√™s: {english} | Espanhol: {spanish}\")\n",
        "    print(f\"üìÑ CV (resumo): {cv_excerpt}\\n\")\n",
        "    print('\\n--------------------------------------------------------------------\\n')\n",
        "\n",
        "    # Job recommendations\n",
        "    sim_scores = similarity_matrix[applicant_index]\n",
        "    top_indices = sim_scores.argsort()[::-1][:top_n]\n",
        "\n",
        "    for j in top_indices:\n",
        "        job_id = job_ids[j]\n",
        "        job = jobs.get(job_id, {})\n",
        "        job_title = job.get(\"informacoes_basicas\", {}).get(\"titulo_vaga\", \"N/A\")\n",
        "        job_area = job.get(\"perfil_vaga\", {}).get(\"areas_atuacao\", \"N/A\")\n",
        "        job_skills = job.get(\"perfil_vaga\", {}).get(\"competencia_tecnicas_e_comportamentais\", \"N/A\")\n",
        "        job_activities = job.get(\"perfil_vaga\", {}).get(\"principais_atividades\", \"N/A\")\n",
        "\n",
        "        print(f\"üîπ Job Recommendation: {job_title} (ID: {job_id})\")\n",
        "        print(f\"   Similarity Score: {sim_scores[j]:.2f}\")\n",
        "        print(f\"   √Årea: {job_area}\")\n",
        "        print(f\"   üîß Compet√™ncias: {job_skills[:250]}...\")\n",
        "        print(f\"   üìã Atividades: {job_activities[:250]}...\\n\")\n",
        "        print('--------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB3JZFE-cBg5"
      },
      "outputs": [],
      "source": [
        "show_recommendations_for_applicant(1, top_n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_applicant_status = defaultdict(dict)\n",
        "\n",
        "# job_id ‚Üí applicant_id ‚Üí status\n",
        "for job_id, job_data in prospects.items():\n",
        "    for prospect in job_data.get(\"prospects\", []):\n",
        "        applicant_id = prospect[\"codigo\"]\n",
        "        status = prospect.get(\"situacao_candidado\", \"\")\n",
        "        job_applicant_status[job_id][applicant_id] = status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_from_status(status):\n",
        "    status = status.lower()\n",
        "    if \"contratado\" in status or \"fechado\" in status or \"encaminhado\" in status:\n",
        "        return 1  # Match\n",
        "    else:\n",
        "        return 0  # no Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "records = []\n",
        "TOP_N = 10\n",
        "\n",
        "for i, applicant_id in enumerate(applicant_ids):\n",
        "    sim_scores = similarity_matrix[i]\n",
        "    top_indices = sim_scores.argsort()[::-1][:TOP_N]\n",
        "\n",
        "    for j in top_indices:\n",
        "        print(i, len(applicant_ids))\n",
        "        job_id = job_ids[j]\n",
        "        sim = sim_scores[j]\n",
        "\n",
        "        status = job_applicant_status.get(job_id, {}).get(applicant_id, \"\")\n",
        "        label = label_from_status(status)\n",
        "\n",
        "        records.append({\n",
        "            \"applicant_id\": applicant_id,\n",
        "            \"job_id\": job_id,\n",
        "            \"similarity_score\": sim,\n",
        "            \"status\": status,\n",
        "            \"label\": label\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df.to_pickle('labeled_df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: simplify to binary classification (predict Hired vs Not Hired)\n",
        "# Usar regulariza√ß√£o/ ressembly / \n",
        "\n",
        "df[\"binary_label\"] = df[\"label\"]\n",
        "\n",
        "X = df[[\"similarity_score\"]]\n",
        "y = df[\"binary_label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(\n",
        "    scale_pos_weight=80000 / 139,  # imbalance ratio\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df.label == 0]\n",
        "df_minority = df[df.label == 1]\n",
        "\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority) * 3,\n",
        "                                   random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_balanced[\"binary_label\"] = df_balanced[\"label\"]\n",
        "\n",
        "X = df_balanced[[\"similarity_score\"]]\n",
        "y = df_balanced[\"binary_label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = XGBClassifier(\n",
        "    scale_pos_weight=80000 / 139,  # imbalance ratio\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_recommendations_for_applicant(applicant_index, top_n=5, model=None):\n",
        "    applicant_id = applicant_ids[applicant_index]\n",
        "    applicant = applicants.get(applicant_id, {})\n",
        "\n",
        "    # Extract applicant details\n",
        "    name = applicant.get(\"infos_basicas\", {}).get(\"nome\", \"N/A\")\n",
        "    area = applicant.get(\"informacoes_profissionais\", {}).get(\"area_atuacao\", \"N/A\")\n",
        "    skills = applicant.get(\"informacoes_profissionais\", {}).get(\"conhecimentos_tecnicos\", \"N/A\")\n",
        "    academic = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_academico\", \"N/A\")\n",
        "    english = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_ingles\", \"N/A\")\n",
        "    spanish = applicant.get(\"formacao_e_idiomas\", {}).get(\"nivel_espanhol\", \"N/A\")\n",
        "    cv_excerpt = applicant.get(\"cv_pt\", \"\").strip().replace(\"\\n\", \" \")[:300] + \"...\"\n",
        "\n",
        "    # Show applicant info once\n",
        "    print(f\"\\n=== üßë Applicant: {name} (ID: {applicant_id}) ===\")\n",
        "    print(f\"√Årea de Atua√ß√£o: {area}\")\n",
        "    print(f\"Conhecimentos T√©cnicos: {skills}\")\n",
        "    print(f\"Forma√ß√£o: {academic} | Ingl√™s: {english} | Espanhol: {spanish}\")\n",
        "    print(f\"üìÑ CV (resumo): {cv_excerpt}\\n\")\n",
        "    print('\\n--------------------------------------------------------------------\\n')\n",
        "\n",
        "    # Job recommendations\n",
        "    sim_scores = similarity_matrix[applicant_index]\n",
        "    top_indices = sim_scores.argsort()[::-1][:top_n]\n",
        "\n",
        "    for j in top_indices:\n",
        "        job_id = job_ids[j]\n",
        "        job = jobs.get(job_id, {})\n",
        "        job_title = job.get(\"informacoes_basicas\", {}).get(\"titulo_vaga\", \"N/A\")\n",
        "        job_area = job.get(\"perfil_vaga\", {}).get(\"areas_atuacao\", \"N/A\")\n",
        "        job_skills = job.get(\"perfil_vaga\", {}).get(\"competencia_tecnicas_e_comportamentais\", \"N/A\")\n",
        "        job_activities = job.get(\"perfil_vaga\", {}).get(\"principais_atividades\", \"N/A\")\n",
        "\n",
        "        # Get similarity score\n",
        "        sim_score = sim_scores[j]\n",
        "\n",
        "        # Use model to predict hire probability\n",
        "        hire_prob = None\n",
        "        if model is not None:\n",
        "            # Model expects 2D array of features\n",
        "            hire_prob = model.predict_proba([[sim_score]])[0][1]  # probability of class 1 (hired)\n",
        "\n",
        "        print(f\"üîπ Job Recommendation: {job_title} (ID: {job_id})\")\n",
        "        print(f\"   Similarity Score: {sim_score:.2f}\")\n",
        "        if hire_prob is not None:\n",
        "            print(f\"   ü§ñ Predicted Hire Probability: {hire_prob:.2%}\")\n",
        "        print(f\"   √Årea: {job_area}\")\n",
        "        print(f\"   üîß Compet√™ncias: {job_skills[:250]}...\")\n",
        "        print(f\"   üìã Atividades: {job_activities[:250]}...\\n\")\n",
        "        print('--------------------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After training your model...\n",
        "show_recommendations_for_applicant(applicant_index=300, top_n=5, model=model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')  # good multilingual model\n",
        "\n",
        "# Convert preprocessed text\n",
        "applicant_embeddings = model.encode(applicant_texts, show_progress_bar=True)\n",
        "job_embeddings = model.encode(job_texts, show_progress_bar=True)\n",
        "\n",
        "# Similarity matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity(applicant_embeddings, job_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#np.save('similarity_matrix_emb', similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_recommendations_for_applicant(1, top_n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "records = []\n",
        "TOP_N = 10\n",
        "\n",
        "for i, applicant_id in enumerate(applicant_ids):\n",
        "    sim_scores = similarity_matrix[i]\n",
        "    top_indices = sim_scores.argsort()[::-1][:TOP_N]\n",
        "\n",
        "    for j in top_indices:\n",
        "        print(i, len(applicant_ids))\n",
        "        job_id = job_ids[j]\n",
        "        sim = sim_scores[j]\n",
        "\n",
        "        status = job_applicant_status.get(job_id, {}).get(applicant_id, \"\")\n",
        "        label = label_from_status(status)\n",
        "\n",
        "        records.append({\n",
        "            \"applicant_id\": applicant_id,\n",
        "            \"job_id\": job_id,\n",
        "            \"similarity_score\": sim,\n",
        "            \"status\": status,\n",
        "            \"label\": label\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df.to_pickle('labeled_df_emb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_majority = df[df.label == 0]\n",
        "df_minority = df[df.label == 1]\n",
        "\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority) * 3,\n",
        "                                   random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_balanced[\"binary_label\"] = df_balanced[\"label\"]\n",
        "\n",
        "X = df_balanced[[\"similarity_score\"]]\n",
        "y = df_balanced[\"binary_label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = XGBClassifier(\n",
        "    scale_pos_weight=80000 / 139,  # imbalance ratio\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_recommendations_for_applicant(applicant_index=300, top_n=5, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
