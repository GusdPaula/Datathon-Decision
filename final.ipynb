{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f341d9",
   "metadata": {},
   "source": [
    "# Final notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976fc04c",
   "metadata": {},
   "source": [
    "En: This notebook is used to create the final code to be used in the front-end app done with streamlit.\n",
    "Pt: Este notebook foi usando para criar a vers√£o final do c√≥digo que ser√° usado no app fron-end criado com streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f983be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs/ importando libs\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "import warnings\n",
    "import fitz\n",
    "import pickle\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Reading the jobs data/ lendo os dados de vagas\n",
    "with open(\"vagas.pkl\", \"rb\") as f:\n",
    "    jobs = pickle.load(f)\n",
    "\n",
    "# Loading models/ Carregando os modelos\n",
    "logreg = joblib.load(\"logistic_model.pkl\")\n",
    "xgb = joblib.load(\"xgboost_model.pkl\")\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Getting the jobs embeddings' data/ Obtendo os embeddings dos dados de vagas\n",
    "job_data = joblib.load(\"job_data.pkl\")\n",
    "job_ids = job_data[\"job_ids\"]\n",
    "job_titles = job_data[\"job_titles\"]\n",
    "job_embeddings = job_data[\"job_embeddings\"]\n",
    "\n",
    "# Function that will process the CV text/ Fun√ß√£o que processar√° o texto do CV.\n",
    "def preprocess(text):\n",
    "    import re, string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text, language=\"portuguese\")\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will use the loaded models and embeddings to calculate similarity and predict the probability to be hired from one uploaded CV.\n",
    "# Esta fun√ß√£o usar√° os modelos carregados e embeddings para calcular a similaridade e predizer a probabilidade de ser contratado com o text de um CV.\n",
    "def predict_jobs_for_cv(cv_text, top_n=5):\n",
    "\n",
    "    # Precessing and cleaning CV text/ Preccessando e limpando texto do CV\n",
    "    cleaned_cv = preprocess(cv_text)\n",
    "\n",
    "    # Calculate the CV text embedding/ calculando o embedding do texto do cv\n",
    "    cv_vec = embedding_model.encode([cleaned_cv])\n",
    "    \n",
    "    # Calculating the similirarity between jobs and cv vectors\n",
    "    # Calculando similiridade entre vetores de vagas e do cv\n",
    "    sims = cosine_similarity(cv_vec, job_embeddings).flatten()\n",
    "\n",
    "\n",
    "    # Looping through the jobs, calculating the hire probability and getting job's data\n",
    "    # Iterando pelas vagas, calculando a probilidade de ser contratado e obtendo informa√ß√µes das vagas\n",
    "\n",
    "    results = []\n",
    "    for i, sim in enumerate(sims):\n",
    "        # Predicting the hire probability/ Predizendo a probabilidade de ser contratado\n",
    "        logreg_prob = logreg.predict_proba([[sim]])[0][1]\n",
    "        xgb_prob = xgb.predict_proba([[sim]])[0][1]\n",
    "        ensemble_prob = (logreg_prob + xgb_prob) / 2\n",
    "\n",
    "        # Getting the jobs' data/ Obtendo dados das vagas\n",
    "        job = jobs.get(job_ids[i], {})\n",
    "        title = job.get(\"informacoes_basicas\", {}).get(\"titulo_vaga\", \"N/A\")\n",
    "        area = job.get(\"perfil_vaga\", {}).get(\"areas_atuacao\", \"N/A\")\n",
    "        skills = job.get(\"perfil_vaga\", {}).get(\"competencia_tecnicas_e_comportamentais\", \"\")\n",
    "        activities = job.get(\"perfil_vaga\", {}).get(\"principais_atividades\", \"\")\n",
    "\n",
    "        results.append({\n",
    "            \"job_id\": job_ids[i],\n",
    "            \"title\": title,\n",
    "            \"area\": area,\n",
    "            \"skills\": skills,\n",
    "            \"activities\": activities,\n",
    "            \"similarity\": sim,\n",
    "            \"hire_prob\": ensemble_prob\n",
    "        })\n",
    "\n",
    "    # Sort and display/ Ordenar e mostrar\n",
    "    top_jobs = sorted(results, key=lambda x: x[\"hire_prob\"], reverse=True)[:top_n]\n",
    "\n",
    "    for idx, job in enumerate(top_jobs, 1):\n",
    "        print(f\"\\nüîπ Recommendation #{idx}\")\n",
    "        print(f\"üè¢ Job Title       : {job['title']}\")\n",
    "        print(f\"üìç Area            : {job['area']}\")\n",
    "        print(f\"üìà Similarity Score: {job['similarity']:.2f}\")\n",
    "        print(f\"ü§ñ Hire Probability: {job['hire_prob']:.2%}\")\n",
    "        print(f\"üîß Skills Required : {job['skills'][:200]}...\")\n",
    "        print(f\"üìã Activities      : {job['activities'][:200]}...\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c197d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will convert PDF into TXT/ Fun√ß√£o que converter√° PDF em TXT\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072de17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting CV path/ obtendo caminho do CV\n",
    "cv_path = r\"\" \n",
    "\n",
    "# Converting CV text/ convertendo texto do cv\n",
    "cv_text = extract_text_from_pdf(cv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the above functions/ Usando fun√ß√µes acima\n",
    "top_jobs = predict_jobs_for_cv(cv_text, top_n=5)\n",
    "print(top_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d246b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
